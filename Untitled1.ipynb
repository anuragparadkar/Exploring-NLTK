{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SGhFpMji8mQ",
        "colab_type": "text"
      },
      "source": [
        "## **Analyzing Moby Dick**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LODj_A5eEtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2ew23rpZCjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        " \n",
        "# to work with the raw text you can use 'moby_raw'\n",
        "with open('moby.txt', 'r') as f:\n",
        "    moby_raw = f.read()\n",
        "    \n",
        "# In nltk.Text format you can use 'text1'\n",
        "moby_tokens = nltk.word_tokenize(moby_raw)\n",
        "text1 = nltk.Text(moby_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9ytx2qrfhnn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14b29a63-b232-41d7-e6f9-959689d81bb4"
      },
      "source": [
        "#tokens (words and punctuation symbols) in text1 \n",
        "def example_1():\n",
        "    \n",
        "    return len(nltk.word_tokenize(moby_raw)) \n",
        "\n",
        "example_1()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "254989"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgehQf98ggoK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f74a11af-51a0-4694-b73d-26729eeadb3b"
      },
      "source": [
        "#unique tokens (unique words and punctuation) in text1 \n",
        "\n",
        "\n",
        "def example_2():\n",
        "    \n",
        "    return len(set(nltk.word_tokenize(moby_raw)))\n",
        "\n",
        "example_2()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20755"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX-dDA3Tf2CB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9fbe7f3-093f-4cd7-8333-23edc3df35c5"
      },
      "source": [
        "#After lemmatizing the verbs, no of unique tokens are:\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def example_3():\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized = [lemmatizer.lemmatize(w,'v') for w in text1]\n",
        "\n",
        "    return len(set(lemmatized))\n",
        "\n",
        "example_3()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16900"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAqC8v6pnq7i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "193f464c-1923-4281-fb15-86ddd102bad4"
      },
      "source": [
        "#lexical diversity of the given text input (i.e. ratio of unique tokens to the total number of tokens)\n",
        "\n",
        "def example_4():\n",
        "    \n",
        "    \n",
        "    return example_2()/example_1()\n",
        "\n",
        "example_4()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08139566804842562"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABoSro_LsQ0i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e62521e1-7777-432d-979c-cd5bdb36e78c"
      },
      "source": [
        "nltk.download('wordnet')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg8JBe9jeXIf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "014fa0e7-4b57-4e43-f485-648a3349befc"
      },
      "source": [
        "# what percentage of tokens is 'whale' or 'Whale'\n",
        "def example_5():\n",
        "    \n",
        "    \n",
        "    return (text1.vocab()['whale'] + text1.vocab()['Whale']) / len(nltk.word_tokenize(moby_raw))*100\n",
        "example_5()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4125668166077752"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbIXppBEiR8Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "8c459c54-da7c-4166-eef9-09c35fa53898"
      },
      "source": [
        "# 10 most frequently occurring (unique) tokens in the text? What is their frequency?\n",
        " \n",
        "def example_6():\n",
        "    import operator\n",
        " \n",
        "    return sorted(text1.vocab().items(), key=operator.itemgetter(1), reverse=True)[:10] \n",
        "example_6()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 19204),\n",
              " ('the', 13715),\n",
              " ('.', 7308),\n",
              " ('of', 6513),\n",
              " ('and', 6010),\n",
              " ('a', 4545),\n",
              " ('to', 4515),\n",
              " (';', 4173),\n",
              " ('in', 3908),\n",
              " ('that', 2978)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFGgFyRoi7P7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be2d1736-4ba5-4210-d6d1-b5819ff82913"
      },
      "source": [
        "#tokens having a length of greater than 6 and frequency of more than 150\n",
        "def example_7():\n",
        "    \n",
        "    \n",
        "    return sorted([token for token, freq in text1.vocab().items() if len(token) > 6 and freq > 150]) \n",
        " \n",
        "example_7()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Captain', 'Queequeg', 'Starbuck', 'himself', 'through', 'without']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tszK-vqxorzC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8836ff91-c61f-4b49-be67-8b90b137ed81"
      },
      "source": [
        "#longest word in text1 and that word's length\n",
        "\n",
        "def example_8():\n",
        "    import operator\n",
        "    \n",
        "    return sorted([(token, len(token))for token, freq in text1.vocab().items()], key=operator.itemgetter(1), reverse=True)[0] \n",
        "\n",
        "example_8()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"twelve-o'clock-at-night\", 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbbl9qlbpfmc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "09c5daef-285b-41e2-87cc-0578a0ad30de"
      },
      "source": [
        "# unique words having a  frequency of more than 1500? What is their frequency?\n",
        "def example_9():\n",
        "    import operator\n",
        "    \n",
        "    return sorted([(freq, token) for token, freq in text1.vocab().items() if freq > 1500 and token.isalpha()], key=operator.itemgetter(0), reverse=True) \n",
        "    example_9()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(13715, 'the'),\n",
              " (6513, 'of'),\n",
              " (6010, 'and'),\n",
              " (4545, 'a'),\n",
              " (4515, 'to'),\n",
              " (3908, 'in'),\n",
              " (2978, 'that'),\n",
              " (2459, 'his'),\n",
              " (2196, 'it'),\n",
              " (2097, 'I'),\n",
              " (1722, 'is'),\n",
              " (1659, 'with'),\n",
              " (1658, 'he'),\n",
              " (1639, 'was'),\n",
              " (1620, 'as')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIIZ6UIrqAuH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6189c8c7-4dfb-4afa-98c4-725d02c09fb6"
      },
      "source": [
        "#average number of tokens per sentence?\n",
        "def example_10():\n",
        "    \n",
        "    \n",
        "    return np.mean([len(nltk.word_tokenize(sent)) for sent in nltk.sent_tokenize(moby_raw)])\n",
        "\n",
        "example_10()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25.881952902963864"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    }
  ]
}